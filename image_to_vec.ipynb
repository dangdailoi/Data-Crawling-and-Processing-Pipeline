{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Q2UzCZiEVrpr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cV5T8wVaBfbg"
      },
      "outputs": [],
      "source": [
        "# Tải mô hình VGG16 đã huấn luyện, bỏ đi lớp fully connected để lấy đặc trưng\n",
        "base_model = VGG16(weights='imagenet')\n",
        "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlIW5kE3BhU-"
      },
      "outputs": [],
      "source": [
        "def extract_features(img_path, model):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_data = image.img_to_array(img)\n",
        "    img_data = np.expand_dims(img_data, axis=0)\n",
        "    img_data = preprocess_input(img_data)\n",
        "    features = model.predict(img_data)\n",
        "    return features.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2i3wGkZYBjRS"
      },
      "outputs": [],
      "source": [
        "def build_feature_database(df, image_folder):\n",
        "    features_list = []\n",
        "    for index, row in df.iterrows():\n",
        "        filenames = row['image_filenames']\n",
        "        if isinstance(filenames, str):\n",
        "            filenames = eval(filenames)\n",
        "        if filenames:\n",
        "            for filename in filenames:\n",
        "                img_path = os.path.join(image_folder, filename)\n",
        "                if os.path.exists(img_path):\n",
        "                    features = extract_features(img_path, model)\n",
        "                    features_list.append(features)\n",
        "                else:\n",
        "                    print(f\"File {img_path} not found, skipping.\")\n",
        "        else:\n",
        "            print(f\"No filenames found for index {index}, skipping.\")\n",
        "    features_array = np.array(features_list)\n",
        "    return features_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMjYB7mDdJAM"
      },
      "outputs": [],
      "source": [
        "image_folder = '/content/drive/MyDrive/DS_KLTN/data/images/'\n",
        "updated_df = pd.read_csv('/content/drive/MyDrive/DS_KLTN/data/fashion_vector_with_filenames.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73vH6QURdMvG"
      },
      "outputs": [],
      "source": [
        "features_array = build_feature_database(updated_df, image_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frkX-io0yroC"
      },
      "source": [
        "#### **save model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9txHioJdOYB"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/DS_KLTN/model/image_search.pkl', 'wb') as f:\n",
        "    pickle.dump(features_array, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmtlV71lyysG"
      },
      "source": [
        "#### **save vector và Binary File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFFGhhHRzADS"
      },
      "outputs": [],
      "source": [
        "vector_save_path = '/content/drive/MyDrive/DS_KLTN/data/image_vectors.npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j084HdNsdSZ2"
      },
      "outputs": [],
      "source": [
        "np.save(vector_save_path, features_array)\n",
        "print(f\"Vectors saved successfully to {vector_save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jev241jfb9IQ"
      },
      "source": [
        "### **repair vector image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Aftkgu7cBd6"
      },
      "outputs": [],
      "source": [
        "product_data_path = '/content/drive/MyDrive/DS_KLTN/data/fashion_vector_with_filenames.csv'\n",
        "image_vectors_path = '/content/drive/MyDrive/DS_KLTN/model/image_vectors.npy'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2nNZYJzcDdZ"
      },
      "outputs": [],
      "source": [
        "products_df = pd.read_csv(product_data_path).rename(columns={'id':'product_id'})\n",
        "image_vectors = np.load(image_vectors_path, allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucMzp-YVasTO"
      },
      "outputs": [],
      "source": [
        "# Tạo danh sách để lưu product_id và vector tương ứng\n",
        "vectors = []\n",
        "ids = []\n",
        "\n",
        "vector_index = 0\n",
        "for _, row in products_df.iterrows():\n",
        "    product_id = row['product_id']\n",
        "    image_filenames = eval(row['image_filenames'])  # Chuyển chuỗi thành danh sách\n",
        "\n",
        "    # Với mỗi hình ảnh, kết hợp product_id với vector ảnh\n",
        "    for filename in image_filenames:\n",
        "        ids.append(product_id)\n",
        "        vectors.append(image_vectors[vector_index])\n",
        "        vector_index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYbPeMa5fxQX"
      },
      "outputs": [],
      "source": [
        "# Lưu dictionary chứa id và vectors vào file .npy\n",
        "data_to_save = {\"id\": ids, \"vector\": vectors}\n",
        "np.save('/content/drive/MyDrive/DS_KLTN/model/product_image_vectors.npy', data_to_save, allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whSetp6Zf8Tz"
      },
      "outputs": [],
      "source": [
        "# Load dữ liệu từ file .npy\n",
        "loaded_data = np.load('/content/drive/MyDrive/DS_KLTN/model/product_image_vectors.npy', allow_pickle=True).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKQJ8Njwf96x"
      },
      "outputs": [],
      "source": [
        "# Truy cập các id và vectors\n",
        "ids = loaded_data[\"id\"]\n",
        "vectors = loaded_data[\"vector\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNWRqbytd8F6"
      },
      "outputs": [],
      "source": [
        "# Ví dụ: In ra các id và vector\n",
        "for i, vector in zip(ids, vectors):\n",
        "    print(f\"Product ID: {i}, Vector: {vector}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
